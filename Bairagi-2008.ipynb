{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bairagi et al. (2008) Model Code <a name=\"top\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Instructions](#instructions)\n",
    "    1. [Parameter Optimization Against TSST Data Sets](#TSSTInstructions)\n",
    "    2. [Parameter Optimization Against Basal Data Sets](#basalInstructions)\n",
    "    3. [Running Without Parameter Optimization](#noOptInstructions)\n",
    "2. [Imports](#imports)\n",
    "3. [Parameters and Initial Conditions](#params)\n",
    "4. [Put Raw Data into Arrays](#rawdata)\n",
    "    1. [Concentration Scales](#scales)\n",
    "    2. [Plot Data Sets](#plotdata)\n",
    "5. [Model Function--Includes ODE Solver](#modelfunction)\n",
    "6. [Cost Function Definition](#cost)\n",
    "7. [Run the Optimization](#run)\n",
    "8. [Save Output to File](#saveoutput)\n",
    "9. [Compute Means and Std Devations of Parameters and Output as Table](#paramtable)\n",
    "10. [Plots](#plots)\n",
    "11. [Reproduce Figure 2 from Paper](#figure2)\n",
    "12. [No Optimization Run](#no-opt)\n",
    "13. [Dependencies](#dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions <a name=\"instructions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Optimization Against TSST Data Sets <a name=\"TSSTInstructions\" />\n",
    "\n",
    "**Note:** To quickly run a cell (or a selection of cells), use the shortcut Shift+Enter (or you can also use the button labeled \"Run\" in the toolbar at the top).\n",
    "\n",
    "To run simulations with parameter optimization against TSST data, there is no need to change any cells until the heading **Run the Optimization**. Simply run all cells up to the cell below that heading.\n",
    "\n",
    "In order to set which data set to optimize parameters against, look for the following line of code:\n",
    "    \n",
    "    data_to_match = [nelson.ACTH[:,0], nelson.ACTH[:,1], nelson.cortisol[:,0], nelson.cortisol[:,1]]\n",
    "\n",
    "In order to run against a patient from the TSST data sets, simply change the list entries to reflect the patient number and subject group. The subject groups are:\n",
    "\n",
    "- nelson.melancholicACTH & nelson.melancholicCortisol (15 patients)\n",
    "- nelson.atypicalACTH & nelson.atypicalCortisol (14 patients)\n",
    "- nelson.neitherACTH & nelson.neitherCortisol (14 patients)\n",
    "- nelson.healthyACTH & nelson.healthyCortisol (15 patients)\n",
    "\n",
    "You could also run against the mean of all patients cortisol and ACTH concentration values by using `nelson.ACTH[:,1]` and `nelson.cortisol[:,1]`. Or you can run against the mean of any subgroup using `nelson.<subgroup name>Cortisol_mean[:,1]` and `nelson.<subgroup name>ACTH_mean[:,1]` (for instance `nelson.melancholicCortisol_mean[:,1]` & `nelson.melancholicACTH_mean[:,1]`). \n",
    "\n",
    "Note that the first column in each data set is the time steps, so indexing with `[:,0]` is referring to the time. These are the values we need to set as the first (ACTH time steps) and third (cortisol time steps) indices of the `data_to_match` list.\n",
    "\n",
    "The following are several examples of lists you could use for parameter optimization with explanations:\n",
    "\n",
    "- `nelson.melancholicACTH[:,0], nelson.melancholicACTH[:,1], nelson.melancholicCortisol[:,0], nelson.melancholicCortisol[:,1]`\n",
    "    - The 1st patient in the Melancholic subgroup\n",
    "- `nelson.atypicalACTH[:,0], nelson.atypicalACTH[:,14], nelson.atypicalCortisol[:,0], nelson.atypicalCortisol[:,14]`\n",
    "    - The 14th patient in the Atypical subgroup\n",
    "- `nelson.healthyACTH[:,0], nelson.healthyACTH[:,2], nelson.healthyCortisol[:,0], nelson.healthyCortisol[:,2]`\n",
    "    - The 2nd patient in the Healthy Control group\n",
    "- `nelson.ACTH[:,0], nelson.ACTH[:,1], nelson.cortisol[:,0], nelson.cortisol[:,1]`\n",
    "    - The mean data set for all patients (depressed and control)\n",
    "- `nelson.healthyACTH_mean[:,0], nelson.healthyACTH_mean[:,1], nelson.healthyCortisol_mean[:,0], nelson.healthyCortisol_mean[:,1]`\n",
    "    - The mean of all control patients\n",
    "    \n",
    "Next, you need to decide whether you will optimize any initial conditions (ICs). This can be modified in the function `cost_fun(params)`. In the cost function, we use the first two optimized parameters in the list returned by the optimization algorithm to set the ICs we want to optimize (CRH and GR in this example):\n",
    "\n",
    "    y0 = [params[0], y0[1], y0[2], params[1]]\n",
    "\n",
    "We then need to pass only the remaining parameters in the list to the model, along with the updated ICs in y0:\n",
    "\n",
    "    simData = model(params[1:], y0)\n",
    "    \n",
    "If you want to not optimize any ICs, you would simply comment out the two lines above in `cost_fun()`, and uncomment the line:\n",
    "\n",
    "    #simData = model(params, y0)\n",
    "    \n",
    "In that case, you will likely want to change the ICs for CRH and GR, as they will stay the same for every iteration. Under the heading **Run the Optimization**, the following line should be modified to reflect the desired ICs:\n",
    "\n",
    "    y0 = [0, data_to_match[1][0], data_to_match[3][0]]\n",
    "    \n",
    "Be sure to leave the 2nd and 3rd indices unchanged, as these set the ICs to use the initial values of the real-world data set being matched.\n",
    "\n",
    "At this point, you are ready to run the optimization, so simply run the cells up to the heading **Save Output to File**. This may take some time, so while it is running you can move on to the next steps (if you run a cell while another is processing, it will add it to a queue).\n",
    "\n",
    "**Note:** You also have the option of using a cost function based on the maximum distance between simulation and real-world data. Simply change SSE_cost to MAX_cost, the instructions for function arguments remain the same.\n",
    "\n",
    "The cell directly under the heading **Save Output to File** can be changed so that the root filename matches the simulations being run. This root will be used to save all of the various data and figures generated. The current naming scheme would save the files for 5 iterations of parameter optimization against the mean data set from the Nelson with ICs for CRH and GR optimized as:\n",
    "\n",
    "    filename_root = \"bairagiModel_output/nelson-patientMean-5-iterations-ICOpt\"\n",
    "\n",
    "This saves the files in a subfolder specific to this model, which helps keep files organized when running multiple models.\n",
    "\n",
    "The next few cells create an Excel file containing all of the concentration data and optimized parameter values, and text files containing the initial conditions, parameter bounds and parameter means +- standard deviation across the 5 iterations.\n",
    "\n",
    "The final step after saving the outputs is to plot the simulations against the real-world data. The cell under the heading **Plots** creates an instance of the Visualizer object from the VeVaPy module called visualize. This will start a dialog which asks for several inputs to generate figures as desired.\n",
    "\n",
    "Because of the strange behavior of this model, we have to divide the time steps by 20 in order to get minutes. Though the authors report the model in minutes, it actually seems to be in minutes*20 for some reason (based on verification results).\n",
    "\n",
    "The cell below the initialization of the `Visualizer` object modifies the time steps. Although the time steps are contained in every 4th column starting with 0, we only use the first of these for graphing. Therefore, the following line of code adjusts the time steps to be in minutes:\n",
    "    \n",
    "    simData_all[:,0] = [time/20 for time in simData_all[:,0]]\n",
    "\n",
    "After initialization of the object and modification of the time steps, run its method `make_graphs()`, and it will generate figures using the data you have specified. There are a number of arguments that can be optionally specified for this method, and you can see the recommended values for these in the following function call:\n",
    "\n",
    "    grapher.make_graphs(yaxis_labels = [\"CRH (pmol/L)\", \"ACTH (pmol/L)\", \"Cortisol (micromol/L)\"],\n",
    "                    xaxis_labels = [\"Time (min)\", \"Time (min)\", \"Time (min)\"],\n",
    "                    graph_titles = [\"CRH Concentration\", \"ACTH Concentration\", \"Cortisol Concentration\"],\n",
    "                    savefile = filename_root+'.png')\n",
    "                \n",
    "### Parameter Optimization Against Basal Data Sets <a name=\"basalInstructions\" />\n",
    "\n",
    "Since these data sets have data points over a 24-hour period (1440 minutes), rather than 140.01 minutes, you will need to change the time interval over which the ODE solver integrates. Strangely, this model seems to be off by a factor of 20 in the time scale, so 140 minutes becomes 2800 time steps--and 1455 minutes becomes 29100 time steps. The reason you add the extra 15 minutes is that you need to make sure that when you interpolate between your simulated data points the line covers every real-world data point so that you don't cause issues when computing the cost function (and the last data point for the Golier cortisol concentration data sets is at 1455 minutes).\n",
    "\n",
    "To change the time scale, go to the cell directly above the heading **Put Raw Data Into Arrays** and uncomment (delete the # at the start of the line) the lines:\n",
    "\n",
    "    t_start = -0.5\n",
    "    t_end = 29100.5\n",
    "    t_step = 0.5\n",
    "\n",
    "You'll need to comment out the other definitons for these variables (place a # at the start of the line).\n",
    "\n",
    "After making this change, you need to again change the `data_to_match` list so that you are matching the basal data set in which you are interested. This time, however, you will also need to change the first and third indices, because we need to tell the function the correct time steps for the data set.\n",
    "\n",
    "First, choose which data set you wish to match. Here are the options:\n",
    "\n",
    "- yehuda.controlCortisol\n",
    "- yehuda.PTSDCortisol\n",
    "- yehuda.depressedCortisol\n",
    "- carroll.controlCortisol & carroll.controlACTH\n",
    "- carroll.LCDepressedCortisol & carroll.LCDepressedACTH (LC = Low Cortisol)\n",
    "- carroll.HCDepressedCortisol & carroll.HCDepressedACTH (HC = High Cortisol)\n",
    "- golier.PTSDCortisol & golierPTSDACTH\n",
    "- golier.nonPTSDTraumaExposedCortisol & golier.nonPTSDTraumaExposedACTH\n",
    "- golier.nonPTSDNonExposedCortisol & golier.nonPTSDNonExposedACTH\n",
    "- bremner.abusedPTSDCortisol\n",
    "- bremner.nonAbusedPTSDCortisol\n",
    "- bremner.nonAbusedNonPTSDCortisol\n",
    "\n",
    "**Note:** To see what any of these data sets looks like, click on the **Plot Basal Data Sets** heading in the Table of Contents.\n",
    "\n",
    "**Note Also:** These data sets all come in smoothed versions (each data point is set to the average of the nearest 5 points of the unsmoothed data). Also, the data sets by Carroll, Golier and Bremner also come in rearranged (or smoothed & rearranged) versions to match the starting time of the Yehuda data (10AM). To use any of these versions, simply append one of the following tags to the end of the data set name (before the indices): `_smooth`, `_rearr`, or `_rearr_smooth`.\n",
    "\n",
    "First, I will cover what to do with data sets that contain both ACTH and cortisol values, and then afterwards I will cover using the Yehuda and Bremner data sets (which have only cortisol concentration data). Just as with the Nelson data, in all of these data sets the first column is the time step values. This means that if you take any of these arrays and index it with `[:,0]`, you are referring to the time steps. These are the values we need to use as the first (ACTH time steps) and third (cortisol time steps) indices in the `data_to_match` list.\n",
    "\n",
    "Then for the second and fourth indices, you index the same data sets with `[:,1]` to mean the second column (which contains the mean concentration values for each patient group).\n",
    "\n",
    "Here are a couple of examples showing lists you can use for optimization:\n",
    "\n",
    "- `carroll.controlACTH_smooth[:,0], carroll.controlACTH_smooth[:,1], carroll.controlCortisol_smooth[:,0], carroll.controlCortisol_smooth[:,1]`\n",
    "    - The smoothed Control group mean for the Carroll data set\n",
    "- `golier.nonPTSDTraumaExposedACTH[:,0], golier.nonPTSDTraumaExposedACTH[:,1], golier.nonPTSDTraumaExposedCortisol[:,0], golier.nonPTSDTraumaExposedCortisol[:,1]`\n",
    "    - The Trauma-Exposed Control group mean for the Golier data set\n",
    "    \n",
    "In order to run simulations against data sets that do not include ACTH concentration data, you will need to change the name of the cost function to `optimize.SSE_cost_noACTH` and then update `data_to_match` to not include the two arguments for ACTH data. To use the Yehuda Control group data, this would look like:\n",
    "\n",
    "    data_to_match = [yehuda.controlCortisol[:,0], yehuda.controlCortisol[:,1]]\n",
    "    return optimize.SSE_cost_noACTH(data_to_match[0], data_to_match[1], simData)\n",
    "\n",
    "For data without ACTH concentrations, you will also need to comment out the current definition of `y0` and uncomment the following line (and change the ICs to the desired values for CRH and ACTH):\n",
    "\n",
    "    #y0 = [0, 10, data_to_match[1][0]]\n",
    "\n",
    "At this point, for data with or without ACTH, you're ready to run the parameter optimization, so run all of the cells under the heading **Run the Optimization**.\n",
    "\n",
    "The cell directly under the heading **Save Output to File** should again have the filename changed to something that reflects the data set you're matching now. For instance, the filename root when matching the smoothed Carroll Control group and optimizing ICs would become:\n",
    "\n",
    "    filename_root = 'bairagiModel_output/carroll-control-smooth-5-iterations-ICopt'\n",
    "            \n",
    "Finally, the cells under the heading **Plots** should be run again to generate graphs. The same process of giving inputs to the object dialog will be performed and then the method `make_graphs()` should be run with any optional arguments desired.\n",
    "\n",
    "### Running Without Parameter Optimization <a name=\"noOptInstructions\" />\n",
    "\n",
    "To reproduce Figure 2 from the Bairagi et al. (2008) paper, you don't need to edit any code. Simply run the cells in the section labeled **Reproducing Figure 2 from Paper**.\n",
    "\n",
    "To run the model with any set of paramaters you desire, without optimization, you can use the cells under the heading **No Optimization Run**. Change the parameters and initial conditions defined under the heading **Parameters and Initial Conditions**, and then run the cell containing the following line:\n",
    "\n",
    "    data_no_opt = model(authors_params, y0)\n",
    "    \n",
    "Then run the cells under **Plots** to create graphs as described in the sections regarding simulations with parameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as sco\n",
    "from scipy import optimize\n",
    "from scipy.interpolate import interp1d\n",
    "import mpld3\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "from VeVaPy import DEsolver, optimize\n",
    "from VeVaPy.dataImport import data\n",
    "from VeVaPy.visualize import Visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters and Initial Conditions <a name=\"params\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions\n",
    "# order: CRH, ACTH, CORT\n",
    "\n",
    "# based on: golierPTSD\n",
    "y0 = [10, 44.22111, 10.68792]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors' listed parameter values\n",
    "b1 = 0.023\n",
    "b2 = 0.04\n",
    "b3 = 0.0083\n",
    "g1 = 0.032\n",
    "g2 = 0.0013\n",
    "V = 3\n",
    "K = 0.048\n",
    "m = 3\n",
    "a1 = 0.015\n",
    "a2 = 0.026\n",
    "\n",
    "# save these parameter values in an array to use when running without optimization\n",
    "authors_params = [b1, b2, b3, g1, g2, V, K, m, a1, a2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time delay parameters, as used in Figure 2 from the paper\n",
    "tau1 = 30\n",
    "tau2 = 60\n",
    "tau_prime = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bounds based on +- 10%\n",
    "bound = a2\n",
    "print(bound - bound*.1)\n",
    "print(bound + bound*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounds for parameter optimization\n",
    "# starting with +- 10% since we do not have published ranges in the paper\n",
    "# order is: b1, b2, b3, g1, g2, V, K, m, a1, a2\n",
    "bounds = [(0, 20), (0.0207, 0.0253), (0.036000000000000004, 0.044), (0.00747, 0.00913), (0.0288, 0.0352), (0.00117, 0.0014299999999999998), (2.7, 3.3), (0.0432, 0.0528), (2.7, 3.3), (0.0135, 0.0165), (0.023399999999999997, 0.0286)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time interval for integration\n",
    "\n",
    "# time interval and step definition\n",
    "# all data sets end on 1440.0 or earlier except the Golier cortisol sets,\n",
    "# they end on 1455.0, so I should set t_end = 1455.01 when matching them\n",
    "#\n",
    "# strangely, the model seems to be off by a multiple of 20 in terms of the time step\n",
    "# in order to match the data for 100 minutes from the authors in Figure 2, I had to run the code for 2000 minutes\n",
    "#t_start = -0.5\n",
    "#t_end = 28800.5\n",
    "#t_step = 0.5\n",
    "\n",
    "# for matching Nelson data, use these values of t_start, t_end and t_step\n",
    "#\n",
    "# the factor of 20 here makes the last time step 2800 for the Nelson data\n",
    "t_start = -0.5\n",
    "t_end = 2800.5\n",
    "t_step = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put Raw Data into Arrays <a name=\"rawdata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the data class for each data set contained in the VeVaPy library, and set the time\n",
    "# scale to minutes.\n",
    "yehuda = data(\"yehuda\", \"minutes\")\n",
    "carroll = data(\"carroll\", \"minutes\")\n",
    "golier = data(\"golier\", \"minutes\")\n",
    "bremner = data(\"bremner\", \"minutes\")\n",
    "nelson = data(\"nelson\", \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concentration Scales <a name=\"scales\" />\n",
    "This model actually computes CRH, ACTH and Cortisol in pmol/L, rather than having the usual units of micrograms/dL and picograms/mL.\n",
    "\n",
    "Therefore, we need to convert the scale of the data sets.\n",
    "\n",
    "### For conversion of data to moles:\n",
    "\n",
    "ACTH = 2933.444 g/mol\n",
    "\n",
    "Cortisol = 362.46 g/mol\n",
    "\n",
    "### Then we need to make the following conversions:\n",
    "x pg/mL ACTH = x/2933.444e9 mol/L ACTH = x/2.933444e12 mol/L ACTH = x/2.933444 pmol/L ACTH\n",
    "\n",
    "x micrograms/dL Cortisol = x/362.46e5 mol/L Cortisol = x/3.6246e7 mol/L Cortisol = x/3.6246e-5 pmol/L Cortisol\n",
    "\n",
    "However, based on the graphs in the paper, I think the authors meant to use micromolar for the cortisol concentrations, because they report ~0.5-1 and this data is 35-40k if we use picomolar. So here I'm using x/3.6246e1 to get micromolar for the cortisol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carroll.controlACTH[:,1] = np.divide(carroll.controlACTH[:,1], 2.933444)\n",
    "carroll.controlACTH_rearr[:,1] = np.divide(carroll.controlACTH_rearr[:,1], 2.933444)\n",
    "carroll.controlACTH_smooth[:,1] = np.divide(carroll.controlACTH_smooth[:,1], 2.933444)\n",
    "carroll.controlACTH_rearr_smooth[:,1] = np.divide(carroll.controlACTH_rearr_smooth[:,1], 2.933444)\n",
    "\n",
    "carroll.controlCortisol[:,1] = np.divide(carroll.controlCortisol[:,1], 3.6246e1)\n",
    "carroll.controlCortisol_rearr[:,1] = np.divide(carroll.controlCortisol_rearr[:,1], 3.6246e1)\n",
    "carroll.controlCortisol_smooth[:,1] = np.divide(carroll.controlCortisol_smooth[:,1], 3.6246e1)\n",
    "carroll.controlCortisol_rearr_smooth[:,1] = np.divide(carroll.controlCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "carroll.HCDepressedACTH[:,1] = np.divide(carroll.HCDepressedACTH[:,1], 2.933444)\n",
    "carroll.HCDepressedACTH_rearr[:,1] = np.divide(carroll.HCDepressedACTH_rearr[:,1], 2.933444)\n",
    "carroll.HCDepressedACTH_smooth[:,1] = np.divide(carroll.HCDepressedACTH_smooth[:,1], 2.933444)\n",
    "carroll.HCDepressedACTH_rearr_smooth[:,1] = np.divide(carroll.HCDepressedACTH_rearr_smooth[:,1], 2.933444)\n",
    "\n",
    "carroll.HCDepressedCortisol[:,1] = np.divide(carroll.HCDepressedCortisol[:,1], 3.6246e1)\n",
    "carroll.HCDepressedCortisol_rearr[:,1] = np.divide(carroll.HCDepressedCortisol_rearr[:,1], 3.6246e1)\n",
    "carroll.HCDepressedCortisol_smooth[:,1] = np.divide(carroll.HCDepressedCortisol_smooth[:,1], 3.6246e1)\n",
    "carroll.HCDepressedCortisol_rearr_smooth[:,1] = np.divide(carroll.HCDepressedCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "carroll.LCDepressedACTH[:,1] = np.divide(carroll.LCDepressedACTH[:,1], 2.933444)\n",
    "carroll.LCDepressedACTH_rearr[:,1] = np.divide(carroll.LCDepressedACTH_rearr[:,1], 2.933444)\n",
    "carroll.LCDepressedACTH_smooth[:,1] = np.divide(carroll.LCDepressedACTH_smooth[:,1], 2.933444)\n",
    "carroll.LCDepressedACTH_rearr_smooth[:,1] = np.divide(carroll.LCDepressedACTH_rearr_smooth[:,1], 2.933444)\n",
    "\n",
    "carroll.LCDepressedCortisol[:,1] = np.divide(carroll.LCDepressedCortisol[:,1], 3.6246e1)\n",
    "carroll.LCDepressedCortisol_rearr[:,1] = np.divide(carroll.LCDepressedCortisol_rearr[:,1], 3.6246e1)\n",
    "carroll.LCDepressedCortisol_smooth[:,1] = np.divide(carroll.LCDepressedCortisol_smooth[:,1], 3.6246e1)\n",
    "carroll.LCDepressedCortisol_rearr_smooth[:,1] = np.divide(carroll.LCDepressedCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "yehuda.controlCortisol[:,1] = np.divide(yehuda.controlCortisol[:,1], 3.6246e1)\n",
    "yehuda.controlCortisol_smooth[:,1] = np.divide(yehuda.controlCortisol_smooth[:,1], 3.6246e1)\n",
    "\n",
    "yehuda.PTSDCortisol[:,1] = np.divide(yehuda.PTSDCortisol[:,1], 3.6246e1)\n",
    "yehuda.PTSDCortisol_smooth[:,1] = yehuda.PTSDCortisol_smooth[:,1]/3.6246e1\n",
    "\n",
    "yehuda.depressedCortisol[:,1] = np.divide(yehuda.depressedCortisol[:,1], 3.6246e1)\n",
    "yehuda.depressedCortisol_smooth[:,1] = np.divide(yehuda.depressedCortisol_smooth[:,1], 3.6246e1)\n",
    "\n",
    "golier.PTSDCortisol[:,1] = np.divide(golier.PTSDCortisol[:,1], 3.6246e1)\n",
    "golier.PTSDCortisol_rearr[:,1] = np.divide(golier.PTSDCortisol_rearr[:,1], 3.6246e1)\n",
    "golier.PTSDCortisol_smooth[:,1] = np.divide(golier.PTSDCortisol_smooth[:,1], 3.6246e1)\n",
    "golier.PTSDCortisol_rearr_smooth[:,1] = np.divide(golier.PTSDCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "golier.PTSDACTH[:,1] = np.divide(golier.PTSDACTH[:,1], 2.933444)\n",
    "golier.PTSDACTH_rearr[:,1] = np.divide(golier.PTSDACTH_rearr[:,1], 2.933444)\n",
    "golier.PTSDACTH_smooth[:,1] = np.divide(golier.PTSDACTH_smooth[:,1], 2.933444)\n",
    "golier.PTSDACTH_rearr_smooth[:,1] = np.divide(golier.PTSDACTH_rearr_smooth[:,1], 2.933444)\n",
    "\n",
    "golier.nonPTSDTraumaExposedCortisol[:,1] = np.divide(golier.nonPTSDTraumaExposedCortisol[:,1], 3.6246e1)\n",
    "golier.nonPTSDTraumaExposedCortisol_rearr[:,1] = np.divide(golier.nonPTSDTraumaExposedCortisol_rearr[:,1], 3.6246e1)\n",
    "golier.nonPTSDTraumaExposedCortisol_smooth[:,1] = np.divide(golier.nonPTSDTraumaExposedCortisol_smooth[:,1], 3.6246e1)\n",
    "golier.nonPTSDTraumaExposedCortisol_rearr_smooth[:,1] = np.divide(golier.nonPTSDTraumaExposedCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "golier.nonPTSDTraumaExposedACTH[:,1] = np.divide(golier.nonPTSDTraumaExposedACTH[:,1], 2.933444)\n",
    "golier.nonPTSDTraumaExposedACTH_rearr[:,1] = np.divide(golier.nonPTSDTraumaExposedACTH_rearr[:,1], 2.933444)\n",
    "golier.nonPTSDTraumaExposedACTH_smooth[:,1] = np.divide(golier.nonPTSDTraumaExposedACTH_smooth[:,1], 2.933444)\n",
    "golier.nonPTSDTraumaExposedACTH_rearr_smooth[:,1] = np.divide(golier.nonPTSDTraumaExposedACTH_rearr_smooth[:,1], 2.933444)\n",
    "\n",
    "golier.nonPTSDNonExposedCortisol[:,1] = np.divide(golier.nonPTSDNonExposedCortisol[:,1], 3.6246e1)\n",
    "golier.nonPTSDNonExposedCortisol_rearr[:,1] = np.divide(golier.nonPTSDNonExposedCortisol_rearr[:,1], 3.6246e1)\n",
    "golier.nonPTSDNonExposedCortisol_smooth[:,1] = np.divide(golier.nonPTSDNonExposedCortisol_smooth[:,1], 3.6246e1)\n",
    "golier.nonPTSDNonExposedCortisol_rearr_smooth[:,1] = np.divide(golier.nonPTSDNonExposedCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "golier.nonPTSDNonExposedACTH[:,1] = np.divide(golier.nonPTSDNonExposedACTH[:,1], 2.933444)\n",
    "golier.nonPTSDNonExposedACTH_rearr[:,1] = np.divide(golier.nonPTSDNonExposedACTH_rearr[:,1], 2.933444)\n",
    "golier.nonPTSDNonExposedACTH_smooth[:,1] = np.divide(golier.nonPTSDNonExposedACTH_smooth[:,1], 2.933444)\n",
    "golier.nonPTSDNonExposedACTH_rearr_smooth[:,1] = np.divide(golier.nonPTSDNonExposedACTH_rearr_smooth[:,1], 2.933444)\n",
    "\n",
    "bremner.abusedPTSDCortisol[:,1] = np.divide(bremner.abusedPTSDCortisol[:,1], 3.6246e1)\n",
    "bremner.abusedPTSDCortisol_rearr[:,1] = np.divide(bremner.abusedPTSDCortisol_rearr[:,1], 3.6246e1)\n",
    "bremner.abusedPTSDCortisol_smooth[:,1] = np.divide(bremner.abusedPTSDCortisol_smooth[:,1], 3.6246e1)\n",
    "bremner.abusedPTSDCortisol_rearr_smooth[:,1] = np.divide(bremner.abusedPTSDCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "bremner.nonAbusedPTSDCortisol[:,1] = np.divide(bremner.nonAbusedPTSDCortisol[:,1], 3.6246e1)\n",
    "bremner.nonAbusedPTSDCortisol_rearr[:,1] = np.divide(bremner.nonAbusedPTSDCortisol_rearr[:,1], 3.6246e1)\n",
    "bremner.nonAbusedPTSDCortisol_smooth[:,1] = np.divide(bremner.nonAbusedPTSDCortisol_smooth[:,1], 3.6246e1)\n",
    "bremner.nonAbusedPTSDCortisol_rearr_smooth[:,1] = np.divide(bremner.nonAbusedPTSDCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "bremner.nonAbusedNonPTSDCortisol[:,1] = np.divide(bremner.nonAbusedNonPTSDCortisol[:,1], 3.6246e1)\n",
    "bremner.nonAbusedNonPTSDCortisol_rearr[:,1] = np.divide(bremner.nonAbusedNonPTSDCortisol_rearr[:,1], 3.6246e1)\n",
    "bremner.nonAbusedNonPTSDCortisol_smooth[:,1] = np.divide(bremner.nonAbusedNonPTSDCortisol_smooth[:,1], 3.6246e1)\n",
    "bremner.nonAbusedNonPTSDCortisol_rearr_smooth[:,1] = np.divide(bremner.nonAbusedNonPTSDCortisol_rearr_smooth[:,1], 3.6246e1)\n",
    "\n",
    "nelson.ACTH[:, 1:] = np.divide(nelson.ACTH[:, 1:], 2.933444)\n",
    "nelson.cortisol[:, 1:] = np.divide(nelson.cortisol[:, 1:], 3.6246e1)\n",
    "\n",
    "nelson.atypicalACTH[:, 1:] = np.divide(nelson.atypicalACTH[:, 1:], 2.933444)\n",
    "nelson.atypicalCortisol[:, 1:] = np.divide(nelson.atypicalCortisol[:, 1:], 3.6246e1)\n",
    "nelson.melancholicACTH[:, 1:] = np.divide(nelson.melancholicACTH[:, 1:], 2.933444)\n",
    "nelson.melancholicCortisol[:, 1:] = np.divide(nelson.melancholicCortisol[:, 1:], 3.6246e1)\n",
    "nelson.neitherACTH[:, 1:] = np.divide(nelson.neitherACTH[:, 1:], 2.933444)\n",
    "nelson.neitherCortisol[:, 1:] = np.divide(nelson.neitherCortisol[:, 1:], 3.6246e1)\n",
    "nelson.healthyACTH[:, 1:] = np.divide(nelson.healthyACTH[:, 1:], 2.933444)\n",
    "nelson.healthyCortisol[:, 1:] = np.divide(nelson.healthyCortisol[:, 1:], 3.6246e1)\n",
    "\n",
    "nelson.atypicalACTH_mean[:, 1:] = np.divide(nelson.atypicalACTH_mean[:, 1:], 2.933444)\n",
    "nelson.atypicalCortisol_mean[:, 1:] = np.divide(nelson.atypicalCortisol_mean[:, 1:], 3.6246e1)\n",
    "nelson.melancholicACTH_mean[:, 1:] = np.divide(nelson.melancholicACTH_mean[:, 1:], 2.933444)\n",
    "nelson.melancholicCortisol_mean[:, 1:] = np.divide(nelson.melancholicCortisol_mean[:, 1:], 3.6246e1)\n",
    "nelson.neitherACTH_mean[:, 1:] = np.divide(nelson.neitherACTH_mean[:, 1:], 2.933444)\n",
    "nelson.neitherCortisol_mean[:, 1:] = np.divide(nelson.neitherCortisol_mean[:, 1:], 3.6246e1)\n",
    "nelson.healthyACTH_mean[:, 1:] = np.divide(nelson.healthyACTH_mean[:, 1:], 2.933444)\n",
    "nelson.healthyCortisol_mean[:, 1:] = np.divide(nelson.healthyCortisol_mean[:, 1:], 3.6246e1)\n",
    "nelson.depressedACTH_mean[:, 1:] = np.divide(nelson.depressedACTH_mean[:, 1:], 2.933444)\n",
    "nelson.depressedCortisol_mean[:, 1:] = np.divide(nelson.depressedCortisol_mean[:, 1:], 3.6246e1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data Sets <a name=\"plotdata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 3, figsize = (15,15))\n",
    "\n",
    "ax1.plot(yehuda.controlCortisol[:,0], yehuda.controlCortisol[:,1], label = \"Control Group Cortisol\")\n",
    "ax1.plot(yehuda.controlCortisol_smooth[:,0], yehuda.controlCortisol_smooth[:,1], label = \"Control Group Cortisol - Smoothed\")\n",
    "ax1.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (pmol/L)\")\n",
    "ax1.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(yehuda.PTSDCortisol[:,0], yehuda.PTSDCortisol[:,1], label = \"PTSD Group Cortisol\")\n",
    "ax2.plot(yehuda.PTSDCortisol_smooth[:,0], yehuda.PTSDCortisol_smooth[:,1], label = \"PTSD Group Cortisol - Smoothed\")\n",
    "ax2.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (pmol/L)\")\n",
    "ax2.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax3.plot(yehuda.depressedCortisol[:,0], yehuda.depressedCortisol[:,1], label = \"Depression Group Cortisol\")\n",
    "ax3.plot(yehuda.depressedCortisol_smooth[:,0], yehuda.depressedCortisol_smooth[:,1], label = \"Depression Group Cortisol - Smoothed\")\n",
    "ax3.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (pmol/L)\")\n",
    "ax3.legend(loc=\"lower right\", shadow = True, fancybox = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpld3.enable_notebook()\n",
    "%matplotlib inline\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows = 4, figsize = (15,15))\n",
    "\n",
    "ax1.plot(carroll.controlCortisol_rearr[:,0], carroll.controlCortisol_rearr[:,1], 'b', label = \"Control\")\n",
    "ax1.plot(carroll.HCDepressedCortisol_rearr[:,0], carroll.HCDepressedCortisol_rearr[:,1], 'r', label = \"High Cortisol Depressed\")\n",
    "ax1.plot(carroll.controlCortisol_rearr_smooth[:,0], carroll.controlCortisol_rearr_smooth[:,1], label = \"Control - Smoothed\")\n",
    "ax1.plot(carroll.HCDepressedCortisol_rearr_smooth[:,0], carroll.HCDepressedCortisol_rearr_smooth[:,1], label = \"High Cortisol Depressed - Smoothed\")\n",
    "ax1.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (micrograms/dL)\")\n",
    "ax1.legend(loc=\"upper right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(carroll.controlCortisol_rearr[:,0], carroll.controlCortisol_rearr[:,1], 'b', label = \"Control\")\n",
    "ax2.plot(carroll.LCDepressedCortisol_rearr[:,0], carroll.LCDepressedCortisol_rearr[:,1], 'g', label = \"Low Cortisol Depressed\")\n",
    "ax2.plot(carroll.controlCortisol_rearr_smooth[:,0], carroll.controlCortisol_rearr_smooth[:,1], label = \"Control - Smoothed\")\n",
    "ax2.plot(carroll.LCDepressedCortisol_rearr_smooth[:,0], carroll.LCDepressedCortisol_rearr_smooth[:,1], label = \"Low Cortisol Depressed - Smoothed\")\n",
    "ax2.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (micrograms/dL)\")\n",
    "ax2.legend(loc=\"upper right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax3.plot(carroll.controlACTH_rearr[:,0], carroll.controlACTH_rearr[:,1], 'b', label = \"Control\")\n",
    "ax3.plot(carroll.HCDepressedACTH_rearr[:,0], carroll.HCDepressedACTH_rearr[:,1], 'r', label = \"High Cortisol Depressed\")\n",
    "ax3.plot(carroll.controlACTH_rearr_smooth[:,0], carroll.controlACTH_rearr_smooth[:,1], label = \"Control - Smoothed\")\n",
    "ax3.plot(carroll.HCDepressedACTH_rearr_smooth[:,0], carroll.HCDepressedACTH_rearr_smooth[:,1], label = \"High Cortisol Depressed - Smoothed\")\n",
    "ax3.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax3.legend(loc=\"upper right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax4.plot(carroll.controlACTH_rearr[:,0], carroll.controlACTH_rearr[:,1], 'b', label = \"Control\")\n",
    "ax4.plot(carroll.LCDepressedACTH_rearr[:,0], carroll.LCDepressedACTH_rearr[:,1], 'g', label = \"Low Cortisol Depressed\")\n",
    "ax4.plot(carroll.controlACTH_rearr_smooth[:,0], carroll.controlACTH_rearr_smooth[:,1], label = \"Control - Smoothed\")\n",
    "ax4.plot(carroll.LCDepressedACTH_rearr_smooth[:,0], carroll.LCDepressedACTH_rearr_smooth[:,1], label = \"Low Cortisol Depressed - Smoothed\")\n",
    "ax4.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax4.legend(loc=\"upper right\", shadow = True, fancybox = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(nrows = 6, figsize = (15,20))\n",
    "\n",
    "ax1.plot(golier.PTSDCortisol_rearr_smooth[:,0], golier.PTSDCortisol_rearr_smooth[:,1], label = \"Trauma Exposed PTSD Cortisol - Smoothed\")\n",
    "ax1.plot(golier.PTSDCortisol_rearr[:,0], golier.PTSDCortisol_rearr[:,1], label = \"Trauma Exposed PTSD Cortisol\")\n",
    "ax1.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (mg/dL)\")\n",
    "ax1.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(golier.nonPTSDTraumaExposedCortisol_rearr_smooth[:,0], golier.nonPTSDTraumaExposedCortisol_rearr_smooth[:,1], label = \"Trauma Exposed Non-PTSD Cortisol - Smoothed\")\n",
    "ax2.plot(golier.nonPTSDTraumaExposedCortisol_rearr[:,0], golier.nonPTSDTraumaExposedCortisol_rearr[:,1], label = \"Trauma Exposed Non-PTSD Cortisol\")\n",
    "ax2.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (mg/dL)\")\n",
    "ax2.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax3.plot(golier.nonPTSDNonExposedCortisol_rearr_smooth[:,0], golier.nonPTSDNonExposedCortisol_rearr_smooth[:,1], label = \"Non-Exposed Non-PTSD Cortisol - Smoothed\")\n",
    "ax3.plot(golier.nonPTSDNonExposedCortisol_rearr[:,0], golier.nonPTSDNonExposedCortisol_rearr[:,1], label = \"Non-Exposed Non-PTSD Cortisol\")\n",
    "ax3.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (mg/dL)\")\n",
    "ax3.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax4.plot(golier.PTSDACTH_rearr_smooth[:,0], golier.PTSDACTH_rearr_smooth[:,1], label = \"Trauma Exposed PTSD ACTH - Smoothed\")\n",
    "ax4.plot(golier.PTSDACTH_rearr[:,0], golier.PTSDACTH_rearr[:,1], label = \"Trauma Exposed PTSD ACTH\")\n",
    "ax4.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax4.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax5.plot(golier.nonPTSDTraumaExposedACTH_rearr_smooth[:,0], golier.nonPTSDTraumaExposedACTH_rearr_smooth[:,1], label = \"Trauma Exposed Non-PTSD ACTH - Smoothed\")\n",
    "ax5.plot(golier.nonPTSDTraumaExposedACTH_rearr[:,0], golier.nonPTSDTraumaExposedACTH_rearr[:,1], label = \"Trauma Exposed Non-PTSD ACTH\")\n",
    "ax5.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax5.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax6.plot(golier.nonPTSDNonExposedACTH_rearr_smooth[:,0], golier.nonPTSDNonExposedACTH_rearr_smooth[:,1], label = \"Non-Exposed Non-PTSD ACTH - Smoothed\")\n",
    "ax6.plot(golier.nonPTSDNonExposedACTH_rearr[:,0], golier.nonPTSDNonExposedACTH_rearr[:,1], label = \"Non-Exposed Non-PTSD ACTH\")\n",
    "ax6.set(xlabel=\"Time (hours)\", ylabel=\"ACTH (pg/mL)\")\n",
    "ax6.legend(loc=\"lower right\", shadow = True, fancybox = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows = 3, figsize = (15,15))\n",
    "\n",
    "ax1.plot(bremner.abusedPTSDCortisol_rearr_smooth[:,0], bremner.abusedPTSDCortisol_rearr_smooth[:,1], label = \"Abused PTSD Cortisol - Smoothed\")\n",
    "ax1.plot(bremner.abusedPTSDCortisol_rearr[:,0], bremner.abusedPTSDCortisol_rearr[:,1], label = \"Abused PTSD Cortisol\")\n",
    "ax1.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (microg/dL)\")\n",
    "ax1.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(bremner.nonAbusedPTSDCortisol_rearr_smooth[:,0], bremner.nonAbusedPTSDCortisol_rearr_smooth[:,1], label = \"Non-Abused PTSD Cortisol - Smoothed\")\n",
    "ax2.plot(bremner.nonAbusedPTSDCortisol_rearr[:,0], bremner.nonAbusedPTSDCortisol_rearr[:,1], label = \"Non-Abused PTSD Cortisol\")\n",
    "ax2.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (microg/dL)\")\n",
    "ax2.legend(loc=\"lower right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax3.plot(bremner.nonAbusedNonPTSDCortisol_rearr_smooth[:,0], bremner.nonAbusedNonPTSDCortisol_rearr_smooth[:,1], label = \"Non-Abused Non-PTSD Cortisol - Smoothed\")\n",
    "ax3.plot(bremner.nonAbusedNonPTSDCortisol_rearr[:,0], bremner.nonAbusedNonPTSDCortisol_rearr[:,1], label = \"Non-Abused Non-PTSD Cortisol\")\n",
    "ax3.set(xlabel=\"Time (hours)\", ylabel=\"Cortisol (microg/dL)\")\n",
    "ax3.legend(loc=\"lower left\", shadow = True, fancybox = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, (ax1, ax2) = plt.subplots(nrows = 2, figsize = (15, 15))\n",
    "\n",
    "ax1.plot(nelson.ACTH[:,0], nelson.ACTH[:,2], label = \"Patient 1 ACTH\")\n",
    "ax1.set(ylabel = \"ACTH (pM/L)\", xlabel = \"Time (min)\", title = \"Nelson Data\")\n",
    "ax1.legend(loc=\"upper right\", shadow = True, fancybox = True)\n",
    "\n",
    "ax2.plot(nelson.cortisol[:,0], nelson.cortisol[:,2], label = \"Patient 1 Cortisol\")\n",
    "ax2.set(ylabel = \"Cortisol (pM/L)\", xlabel = \"Time (min)\")\n",
    "ax2.legend(loc=\"upper right\", shadow = True, fancybox = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function--Includes ODE Solver <a name=\"modelfunction\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(params, ics):\n",
    "    def ode_system(t, y):\n",
    "        dy = np.zeros(3) # 3 equation system, R = CRH, A = ACTH, C = CORT\n",
    "        \n",
    "        [b1, b2, b3, g1, g2, V, K, m, a1, a2] = params\n",
    "        \n",
    "        # differential equation definitions\n",
    "        dy[0] = (a1*V)/(K + (DEsolver.delayedCORT**m)) - b1*y[0]\n",
    "        dy[1] = (a2*V)/(K + (DEsolver.delayedCORT**m)) + g1*DEsolver.delayedCRH - b2*y[1]\n",
    "        dy[2] = g2*DEsolver.delayedACTH - b3*y[2]\n",
    "        \n",
    "        return dy\n",
    "    \n",
    "    # Call the solve() function from my DEsolver module, and pass all of the information it needs.\n",
    "    # Arguments are as follows: ODE function to solve, array of initial conditions, start time, step size, end time\n",
    "    # The last three arguments are optional (leave blank for ODE systems) for delay differential equation systems, \n",
    "    #  tau0 is the delay in CRH, tau1 is the delay in ACTH, tau2 is the delay in CORT, \n",
    "    #  and delay is an array of booleans to set whether we use delays in [CRH, ACTH, CORT]\n",
    "    timeSeries = DEsolver.solve(ode_system, ics, t_start, t_step, t_end, tau0 = 10, tau1 = 30, tau2 = 60, delay = [True, True, True], delay_rough = True)\n",
    "    return timeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function Definition <a name=\"cost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fun(params):\n",
    "    global y0, data_to_match\n",
    "    \n",
    "    # This code will optimize the first initial condition\n",
    "    y0 = [params[0], y0[1], y0[2]]\n",
    "    simData = model(params[1:], y0)\n",
    "    \n",
    "    # Comment both lines above and uncomment below to not match the IC for CRH\n",
    "    # simData = model(params, y0)\n",
    "    \n",
    "    # To optimize ACTH as well as CRH (for use with basal data containing only cortisol concentrations), use\n",
    "    #  the following lines:\n",
    "    #y0 = [params[0], params[1], y0[2]]\n",
    "    #simData = model(params[2:], y0)\n",
    "    # Note that you'll also need to add a bound for the IC of ACTH in the list of parameter bounds\n",
    "    \n",
    "    return optimize.SSE_cost(data_to_match[0], data_to_match[1], data_to_match[2], data_to_match[3], simData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Optimization <a name=\"run\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data set to match with the parameter optimization algorithm.\n",
    "# Requires 4 indices, in the order:\n",
    "# ACTH time steps, ACTH data, Cortisol time steps, Cortisol data\n",
    "data_to_match = [nelson.ACTH[:,0], nelson.ACTH[:,1], nelson.cortisol[:,0], nelson.cortisol[:,1]]\n",
    "\n",
    "# For matching data with only cortisol concentrations, use the following line and change the data sets as desired:\n",
    "#data_to_match = [yehuda.controlCortisol[:,0], yehuda.controlCortisol[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the definition above to fill in the initial conditions for ACTH and cortisol\n",
    "\n",
    "y0 = [0, data_to_match[1][0], data_to_match[3][0]]\n",
    "\n",
    "# For matching data with only cortisol concentrations, use the following line and change the ICs as desired:\n",
    "#y0 = [0, 10, data_to_match[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt_pars, simData_all = optimize.run(cost_fun, model, data_to_match, y0, bounds, ICopt_indices=[0], num_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Output to File <a name=\"saveoutput\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the root filename, this will have the array name appended to it\n",
    "#  to make the filename of the Excel files\n",
    "filename_root = \"bairagiModel_output/nelson-patientMean-5-iterations-ICopt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame object for opt_pars\n",
    "# I've typed out each individual heading for the parameter names that were\n",
    "#  optimized, and assigned the correct column of opt_pars to them\n",
    "df_opt_pars = pd.DataFrame(opt_pars, columns=['Cost',\n",
    "                                              'b1',\n",
    "                                              'b2',\n",
    "                                              'b3',\n",
    "                                              'g1',\n",
    "                                              'g2',\n",
    "                                              'V',\n",
    "                                              'K',\n",
    "                                              'm',\n",
    "                                              'a1',\n",
    "                                              'a2'])\n",
    "\n",
    "# Create the pandas DataFrame object for opt_pars\n",
    "# I've typed out each individual heading for the variables and iterations,\n",
    "# and assigned the correct column of simData_all to them\n",
    "df_simData_all = pd.DataFrame(simData_all, columns=['Iteration 1 Time',\n",
    "                                                    'Iteration 1 CRH',\n",
    "                                                    'Iteration 1 ACTH',\n",
    "                                                    'Iteration 1 Cortisol',\n",
    "                                                    'Iteration 2 Time',\n",
    "                                                    'Iteration 2 CRH',\n",
    "                                                    'Iteration 2 ACTH',\n",
    "                                                    'Iteration 2 Cortisol',\n",
    "                                                    'Iteration 3 Time',\n",
    "                                                    'Iteration 3 CRH',\n",
    "                                                    'Iteration 3 ACTH',\n",
    "                                                    'Iteration 3 Cortisol',\n",
    "                                                    'Iteration 4 Time',\n",
    "                                                    'Iteration 4 CRH',\n",
    "                                                    'Iteration 4 ACTH',\n",
    "                                                    'Iteration 4 Cortisol',\n",
    "                                                    'Iteration 5 Time',\n",
    "                                                    'Iteration 5 CRH',\n",
    "                                                    'Iteration 5 ACTH',\n",
    "                                                    'Iteration 5 Cortisol'])\n",
    "\n",
    "# Create an instance of the ExcelWriter class and open the file using a with statement\n",
    "with pd.ExcelWriter(filename_root+\".xlsx\") as writer:\n",
    "    # Define the header format, so that it's bold, text is wrapped, it has a \n",
    "    #  colored background and a border\n",
    "    header_format = writer.book.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1\n",
    "    })\n",
    "    \n",
    "    # Write the opt_pars array to a sheet in the file, we skip adding in the headers here and add them with the above\n",
    "    #  format afterwards. We also change the row index to start at 1, rather than 0.\n",
    "    df_opt_pars.index = list(range(1,len(opt_pars[:,0])+1))\n",
    "    df_opt_pars.to_excel(writer, sheet_name=\"Optimized Parameters\", startrow=1, header=False)\n",
    "    \n",
    "    # Write the simData_all array to another sheet in the file, we skip adding in the headers here and add them with the above\n",
    "    #  format afterwards. We also disable the row index numbers, as they are not necessary here.\n",
    "    df_simData_all.to_excel(writer, sheet_name=\"Simulated Concentration Data\", startrow=1, header=False, index=False)\n",
    "    \n",
    "    # Loop through each header in opt_pars DataFrame and write to the sheet with formatting\n",
    "    for col,val in enumerate(df_opt_pars.columns.values):\n",
    "        # We write in the sheet \"Optimized Parameters\" in the first row, starting with the second column \n",
    "        #  (because of the row indices), using the headers from the DataFrame and the header format we defined above\n",
    "        writer.sheets[\"Optimized Parameters\"].write(0, col+1, val, header_format)\n",
    "    \n",
    "    # Loop through each header in simData_all DataFrame and write to the sheet with formatting\n",
    "    for col,val in enumerate(df_simData_all.columns.values):\n",
    "        # We write in the sheet \"Simulated Concentration Data\" in the first row, starting with the first column \n",
    "        #  (because we turned off the row indices), using the headers from the DataFrame and \n",
    "        #  the header format we defined above\n",
    "        writer.sheets[\"Simulated Concentration Data\"].write(0, col, val, header_format)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the initial conditions and bounds to text files, also.\n",
    "np.savetxt(filename_root+'-initial-conditions.txt', y0)\n",
    "np.savetxt(filename_root+'-bounds.txt', bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Means and Std Devations of Parameters and Output as Table <a name=\"paramtable\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute parameter means and standard deviations\n",
    "b1_mean = np.mean(opt_pars[:,1])\n",
    "b1_std = np.std(opt_pars[:,1])\n",
    "b2_mean = np.mean(opt_pars[:,1])\n",
    "b2_std = np.std(opt_pars[:,1])\n",
    "b3_mean = np.mean(opt_pars[:,1])\n",
    "b3_std = np.std(opt_pars[:,1])\n",
    "g1_mean = np.mean(opt_pars[:,1])\n",
    "g1_std = np.std(opt_pars[:,1])\n",
    "g2_mean = np.mean(opt_pars[:,1])\n",
    "g2_std = np.std(opt_pars[:,1])\n",
    "V_mean = np.mean(opt_pars[:,1])\n",
    "V_std = np.std(opt_pars[:,1])\n",
    "K_mean = np.mean(opt_pars[:,1])\n",
    "K_std = np.std(opt_pars[:,1])\n",
    "m_mean = np.mean(opt_pars[:,1])\n",
    "m_std = np.std(opt_pars[:,1])\n",
    "a1_mean = np.mean(opt_pars[:,1])\n",
    "a1_std = np.std(opt_pars[:,1])\n",
    "a2_mean = np.mean(opt_pars[:,1])\n",
    "a2_std = np.std(opt_pars[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a table of parameter means and standard deviations\n",
    "print(tabulate([[\"b1\", \"%f +- %f\" % (b1_mean, b1_std)], [\"b2\", \"%f +- %f\" % (b2_mean, b2_std)], [\"b3\", \"%f +- %f\" % (b3_mean, b3_std)], [\"g1\", \"%f +- %f\" % (g1_mean, g1_std)], [\"g2\", \"%f +- %f\" % (g2_mean, g2_std)], [\"V\", \"%f +- %f\" % (V_mean, V_std)], [\"K\", \"%f +- %f\" % (K_mean, K_std)], [\"m\", \"%f +- %f\" % (m_mean, m_std)], [\"a1\", \"%f +- %f\" % (a1_mean, a1_std)], [\"a2\", \"%f +- %f\" % (a2_mean, a2_std)]], headers = [\"Parameter\", \"Mean +- Standard Deviation\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameter means and std devs to a file\n",
    "np.savetxt(filename_root+'-param-means-stds.txt', [b1_mean, b1_std, b2_mean, b2_std, b3_mean, b3_std, g1_mean, g1_std, g2_mean, g2_std, V_mean, V_std, K_mean, K_std, m_mean, m_std, a1_mean, a1_std, a2_mean, a2_std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots <a name=\"plots\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Visualizer object for graphing our simulations\n",
    "grapher = Visualizer(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the strange behavior of this model, we have to multiply the time steps by 3 in order to get seconds.\n",
    "# Though the authors report the model in minutes, it actually seems to be in minutes*20 for some reason (based on\n",
    "# verification results)\n",
    "#\n",
    "# So here, we will modify the time steps. We loop through a range from column 0 to the last column of simData_all,\n",
    "# looking at every 4th column, as these will contain the time steps\n",
    "for i in range(0, len(simData_all[0,:]), 4):\n",
    "    simData_all[:,i] = [time/20 for time in simData_all[:,i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(simData_all[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple graphs\n",
    "grapher.make_graphs(yaxis_labels = [\"CRH (pmol/L)\", \"ACTH (pmol/L)\", \"Cortisol (micromol/L)\"],\n",
    "                    xaxis_labels = [\"Time (min)\", \"Time (min)\", \"Time (min)\"],\n",
    "                    graph_titles = [\"CRH Concentration\", \"ACTH Concentration\", \"Cortisol Concentration\"],\n",
    "                    savefile = filename_root+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce Figure 2 from Paper <a name=\"figure2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorten the time of iteration to see how this delay works\n",
    "t_start = -0.5\n",
    "t_end = 11520.5\n",
    "t_step = 0.5\n",
    "\n",
    "# set the initial conditions\n",
    "y0 = [2.4, 4, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# run the solver with authors' published parameters\n",
    "optimizedSimData = model(authors_params, y0)\n",
    "    \n",
    "# save CRH, cortisol and ACTH data into sims arrays\n",
    "sims_cort = optimizedSimData[:,3]\n",
    "sims_acth = optimizedSimData[:,2]\n",
    "sims_crh = optimizedSimData[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_crh_1440 = sims_crh[-4320:]\n",
    "sims_acth_1440 = sims_acth[-4320:]\n",
    "sims_cort_1440 = sims_cort[-4320:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, (ax1) = plt.subplots(nrows = 1, figsize = (15,15))\n",
    "\n",
    "ax1.plot(optimizedSimData[-4320:,0]/20-470, sims_crh_1440, '-', label = \"CRH\", )\n",
    "ax1.plot(optimizedSimData[-4320:,0]/20-470, sims_acth_1440, ':', label = \"ACTH\")\n",
    "ax1.plot(optimizedSimData[-4320:,0]/20-470, sims_cort_1440, '--', label = \"Cortisol\")\n",
    "ax1.set(ylabel = \"Concentration (pmol/L)\", xlabel = \"Time (mins)\", title = \"Figure 2 Reproduction\")\n",
    "ax1.legend(loc = \"upper right\", shadow = True, fancybox = True)\n",
    "\n",
    "plt.savefig(\"bairagiModel_output/bairagiModel-figure2-reproduction.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Optimization Run <a name='no-opt' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time # Output the runtime of the simulation\n",
    "\n",
    "# Using the parameters and initial conditions defined in the section labeled Parameters and Initial Conditions, run\n",
    "#  a simulation of the model without parameter optimization\n",
    "data_no_opt = model(authors_params, y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies <a name=\"dependencies\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
